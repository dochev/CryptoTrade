{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dochev/CryptoTrade/blob/master/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz2bFAphOJXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git init && git remote add origin https://github.com/dochev/CryptoTrade.git && git pull origin master\n",
        "!git remote set-url origin https://github.com/dochev/CryptoTrade.git\n",
        "# !git clone https://github.com/dochev/CryptoTrade.git\n",
        "# !pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-rS0Gc-qh_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "d0e9636a-48d8-48d1-ef07-97b627b5d8b9"
      },
      "source": [
        "!git fetch origin master"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/dochev/CryptoTrade\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   3b50b9b..86c790d  master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlPw5uPWnQFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6718054b-67be-41b1-93ca-48ffd3de1743"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/dochev/CryptoTrade\n",
            " * branch            master     -> FETCH_HEAD\n",
            "fatal: refusing to merge unrelated histories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_xkujeJPGVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "0ffb3a5e-ed47-4163-8fd2-1548af11dd17"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cli.py             LICENSE                  \u001b[0m\u001b[01;32mrun-with-docker\u001b[0m*\n",
            "\u001b[01;34mconfig\u001b[0m/            optimize.py              \u001b[01;34msample_data\u001b[0m/\n",
            "\u001b[01;34mCryptoTrade\u001b[0m/       README.md                \u001b[01;34mtensortrade\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/              requirements.base.txt    \u001b[01;34mtest\u001b[0m/\n",
            "\u001b[01;32mdev-with-docker\u001b[0m*   requirements.no-gpu.txt  Vagrantfile\n",
            "\u001b[01;34mdocker\u001b[0m/            requirements.tests.txt   visualization.gif\n",
            "Experiments.ipynb  requirements.txt\n",
            "\u001b[01;34mlib\u001b[0m/               \u001b[01;32mrun-tests-with-docker\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1rQ3pw5kE6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9511980-6aa2-4512-96b7-46a27eab7035"
      },
      "source": [
        "%cd CryptoTrade"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CryptoTrade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbZ0ZT8EkqPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cdc36304-1a49-4f91-b163-463940931108"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md  LICENSE      requirements.txt  Welcome_To_Colaboratory.ipynb\n",
            "\u001b[0m\u001b[01;34mdocker\u001b[0m/          Makefile     setup.cfg\n",
            "\u001b[01;34mdocs\u001b[0m/            MANIFEST.in  setup.py\n",
            "\u001b[01;34mexamples\u001b[0m/        README.md    \u001b[01;34mtensortrade\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4XeIUjtPqwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC-2-XghPxKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "warnings.warn = warn\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "\n",
        "from tensortrade.environments import TradingEnvironment\n",
        "from tensortrade.exchanges.simulated import FBMExchange\n",
        "from tensortrade.actions import DiscreteActionStrategy\n",
        "from tensortrade.rewards import SimpleProfitStrategy\n",
        "\n",
        "exchange = FBMExchange()\n",
        "action_strategy = DiscreteActionStrategy()\n",
        "reward_strategy = SimpleProfitStrategy()\n",
        "\n",
        "env = TradingEnvironment(exchange=exchange,\n",
        "                         action_strategy=action_strategy,\n",
        "                         reward_strategy=reward_strategy)\n",
        "\n",
        "obs = env.reset()\n",
        "sell_price = 1e9\n",
        "stop_price = -1\n",
        "\n",
        "# print('Initial portfolio: ', exchange.portfolio)\n",
        "\n",
        "# for i in range(1000):\n",
        "#     action = 0 if obs['close'] < sell_price else 18\n",
        "#     action = 19 if obs['close'] < stop_price else action\n",
        "    \n",
        "#     if i == 0 or portfolio['BTC'] == 0:\n",
        "#         action = 16\n",
        "#         sell_price = obs['close'] + (obs['close'] / 50)\n",
        "#         stop_price = obs['close'] - (obs['close'] / 50)\n",
        "    \n",
        "#     obs, reward, done, info = env.step(action)\n",
        "#     executed_trade = info['executed_trade']\n",
        "#     filled_trade = info['filled_trade']\n",
        "#     portfolio = exchange.portfolio\n",
        "    \n",
        "#     print('Obs: ', obs)\n",
        "#     print('Reward: ', reward)\n",
        "#     print('Portfolio: ', portfolio)\n",
        "#     print('Trade executed: ', executed_trade.trade_type, executed_trade.price, executed_trade.amount)\n",
        "#     print('Trade filled: ', filled_trade.trade_type, filled_trade.price, filled_trade.amount)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wfsRbGPQhQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorforce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzWAxN3qQdnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "c451e1cc-95c2-406f-9c65-9903f0c76789"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "warnings.warn = warn\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "from tensorforce.agents import Agent, DQNAgent\n",
        "from tensorforce.execution import Runner\n",
        "from tensorforce.environments import OpenAIGym\n",
        "\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "\n",
        "from tensortrade.environments import TradingEnvironment\n",
        "from tensortrade.exchanges.simulated import FBMExchange\n",
        "from tensortrade.actions import DiscreteActionStrategy\n",
        "from tensortrade.rewards import SimpleProfitStrategy\n",
        "\n",
        "exchange = FBMExchange(times_to_generate=100000)\n",
        "action_strategy = DiscreteActionStrategy()\n",
        "reward_strategy = SimpleProfitStrategy()\n",
        "\n",
        "env = TradingEnvironment(exchange=exchange,\n",
        "                         action_strategy=action_strategy,\n",
        "                         reward_strategy=reward_strategy,\n",
        "                         feature_pipeline=None)\n",
        "\n",
        "# env = OpenAIGym('CartPole-v0')\n",
        "\n",
        "agent_config = {\n",
        "    \"type\": \"dqn_agent\",\n",
        "\n",
        "    \"update_mode\": {\n",
        "        \"unit\": \"timesteps\",\n",
        "        \"batch_size\": 64,\n",
        "        \"frequency\": 4\n",
        "    },\n",
        "    \n",
        "    \"memory\": {\n",
        "        \"type\": \"replay\",\n",
        "        \"capacity\": 10000,\n",
        "        \"include_next_states\": True\n",
        "    },\n",
        "\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"clipped_step\",\n",
        "        \"clipping_value\": 0.1,\n",
        "        \"optimizer\": {\n",
        "            \"type\": \"adam\",\n",
        "            \"learning_rate\": 1e-3\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"discount\": 0.999,\n",
        "    \"entropy_regularization\": None,\n",
        "    \"double_q_model\": True,\n",
        "\n",
        "    \"target_sync_frequency\": 1000,\n",
        "    \"target_update_weight\": 1.0,\n",
        "\n",
        "    \"actions_exploration\": {\n",
        "        \"type\": \"epsilon_anneal\",\n",
        "        \"initial_epsilon\": 0.5,\n",
        "        \"final_epsilon\": 0.,\n",
        "        \"timesteps\": 1000000000\n",
        "    },\n",
        "\n",
        "    \"saver\": {\n",
        "        \"directory\": None,\n",
        "        \"seconds\": 600\n",
        "    },\n",
        "    \"summarizer\": {\n",
        "        \"directory\": None,\n",
        "        \"labels\": [\"graph\", \"total-loss\"]\n",
        "    },\n",
        "    \"execution\": {\n",
        "        \"type\": \"single\",\n",
        "        \"session_config\": None,\n",
        "        \"distributed_spec\": None\n",
        "    }\n",
        "}\n",
        "\n",
        "network_spec = [\n",
        "    dict(type='dense', size=64, activation='tanh'),\n",
        "    dict(type='dense', size=32, activation='tanh')\n",
        "]\n",
        "  \n",
        "agent = DQNAgent(\n",
        "        states=env.states,\n",
        "        actions=env.actions,\n",
        "        network=network_spec,\n",
        "        batch_size=64\n",
        "#         update=dict(unit='timesteps', batch_size=64),\n",
        "#         objective='policy_gradient',\n",
        "#         reward_estimation=dict(horizon=20)\n",
        "    )\n",
        "\n",
        "# Initialize the agent\n",
        "agent.initialize()\n",
        "\n",
        "# Create the runner\n",
        "runner = Runner(agent=agent, environment=env)\n",
        "\n",
        "# Start learning\n",
        "max_episodes = 300\n",
        "runner.run(max_episodes)\n",
        "runner.close()\n",
        "\n",
        "# Print statistics\n",
        "print(\"Learning finished. Total episodes: {ep}. Average reward of last 100 episodes: {ar}.\".format(\n",
        "    ep=runner.episode,\n",
        "    ar=np.mean(runner.episode_rewards))\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-178b23c213c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Create the runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# Start learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorforce/execution/runner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, agent, environment, evaluation_environment, save_best_agent)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# save_best overwrites saver...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_environment_external\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eval_environment_external\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_environment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorforce/environments/environment.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(environment, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40x7Tu90SHtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "from sklearn import preprocessing\n",
        "\n",
        "class BitcoinTradingEnv(gym.Env):\n",
        "  \"\"\"A Bitcoin trading environment for OpenAI gym\"\"\"\n",
        "  metadata = {'render.modes': ['live', 'file', 'none']}\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  viewer = None\n",
        "  def __init__(self, df, lookback_window_size=50, \n",
        "                         commission=0.00075,  \n",
        "                         initial_balance=10000,\n",
        "                         serial=False):\n",
        "    super(BitcoinTradingEnv, self).__init__()\n",
        "    self.df = df.dropna().reset_index()\n",
        "    self.lookback_window_size = lookback_window_size\n",
        "    self.initial_balance = initial_balance\n",
        "    self.commission = commission\n",
        "    self.serial = serial\n",
        "  # Actions of the format Buy 1/10, Sell 3/10, Hold, etc.\n",
        "    self.action_space = spaces.MultiDiscrete([3, 10])\n",
        "  # Observes the OHCLV values, net worth, and trade history\n",
        "    self.observation_space = spaces.Box(low=0, high=1, shape=(10, \n",
        "                    lookback_window_size + 1), dtype=np.float16)\n",
        "    \n",
        "  def reset(self):\n",
        "    self.balance = self.initial_balance\n",
        "    self.net_worth = self.initial_balance\n",
        "    self.btc_held = 0\n",
        "    self._reset_session()\n",
        "    self.account_history = np.repeat([\n",
        "      [self.net_worth],\n",
        "      [0],\n",
        "      [0],\n",
        "      [0],\n",
        "      [0]\n",
        "    ], self.lookback_window_size + 1, axis=1)\n",
        "    self.trades = []\n",
        "    return self._next_observation()\n",
        "\n",
        "  MAX_TRADING_SESSION = 100000  # ~2 months\n",
        "\n",
        "  def _reset_session(self):\n",
        "    self.current_step = 0\n",
        "    if self.serial:\n",
        "      self.steps_left = len(self.df) - self.lookback_window_size - 1\n",
        "      self.frame_start = self.lookback_window_size\n",
        "    else:\n",
        "      self.steps_left = np.random.randint(1, MAX_TRADING_SESSION)\n",
        "      self.frame_start = np.random.randint(\n",
        "           self.lookback_window_size, len(self.df) - self.steps_left)\n",
        "    self.active_df = self.df[self.frame_start -   \n",
        "         self.lookback_window_size:self.frame_start + self.steps_left]\n",
        "\n",
        "  def _next_observation(self):\n",
        "    end = self.current_step + self.lookback_window_size + 1\n",
        "    obs = np.array([\n",
        "      self.active_df['Open'].values[self.current_step:end],  \n",
        "      self.active_df['High'].values[self.current_step:end],\n",
        "      self.active_df['Low'].values[self.current_step:end],\n",
        "      self.active_df['Close'].values[self.current_step:end],\n",
        "      self.active_df['Volume_(BTC)'].values[self.current_step:end],\n",
        "    ])\n",
        "    scaled_history = self.scaler.fit_transform(self.account_history)\n",
        "    obs = np.append(obs, scaled_history[:, -(self.lookback_window_size\n",
        "                                                       + 1):], axis=0)\n",
        "    return obs\n",
        "\n",
        "  def step(self, action):\n",
        "    current_price = self._get_current_price() + 0.01\n",
        "    self._take_action(action, current_price)\n",
        "    self.steps_left -= 1\n",
        "    self.current_step += 1\n",
        "    if self.steps_left == 0:\n",
        "      self.balance += self.btc_held * current_price\n",
        "      self.btc_held = 0\n",
        "      self._reset_session()\n",
        "    obs = self._next_observation()\n",
        "    reward = self.net_worth\n",
        "    done = self.net_worth <= 0\n",
        "    return obs, reward, done, {}\n",
        "\n",
        "  def _take_action(self, action, current_price):\n",
        "    action_type = action[0]\n",
        "    amount = action[1] / 10\n",
        "    btc_bought = 0\n",
        "    btc_sold = 0\n",
        "    cost = 0\n",
        "    sales = 0\n",
        "    if action_type < 1:\n",
        "      btc_bought = self.balance / current_price * amount\n",
        "      cost = btc_bought * current_price * (1 + self.commission)\n",
        "      self.btc_held += btc_bought\n",
        "      self.balance -= cost\n",
        "    elif action_type < 2:\n",
        "      btc_sold = self.btc_held * amount\n",
        "      sales = btc_sold * current_price  * (1 - self.commission)\n",
        "      self.btc_held -= btc_sold\n",
        "      self.balance += sales\n",
        "    if btc_sold > 0 or btc_bought > 0:\n",
        "      self.trades.append({\n",
        "        'step': self.frame_start+self.current_step,\n",
        "        'amount': btc_sold if btc_sold > 0 else btc_bought,\n",
        "        'total': sales if btc_sold > 0 else cost,\n",
        "        'type': \"sell\" if btc_sold > 0 else \"buy\"\n",
        "      })\n",
        "    self.net_worth = self.balance + self.btc_held * current_price\n",
        "    self.account_history = np.append(self.account_history, [\n",
        "      [self.net_worth],\n",
        "      [btc_bought],\n",
        "      [cost],\n",
        "      [btc_sold],\n",
        "      [sales]\n",
        "    ], axis=1)\n",
        "\n",
        "\n",
        "#   from datetime import datetime\n",
        "#   date_labels = np.array([datetime.utcfromtimestamp(x).strftime(\n",
        "#   '%Y-%m-%d %H:%M') for x in self.df['Timestamp'].values[step_range]])\n",
        "\n",
        "  def render(self, mode='human', **kwargs):\n",
        "    if mode == 'human':\n",
        "      if self.viewer == None:\n",
        "        self.viewer = BitcoinTradingGraph(self.df,\n",
        "                                          kwargs.get('title', None))\n",
        "      self.viewer.render(self.frame_start + self.current_step,\n",
        "                         self.net_worth,\n",
        "                         self.trades,\n",
        "                         window_size=self.lookback_window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiKSVrfaD7vM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ba5b9d0d-7a4b-4833-a346-b04115c9a7f8"
      },
      "source": [
        "df = pd.read_csv(\"../data/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv\")\n",
        "slice_point = int(len(df) - 100000)\n",
        "train_df = df[:slice_point]\n",
        "test_df = df[slice_point:]\n",
        "\n",
        "train_env = DummyVecEnv([lambda: BitcoinTradingEnv(train_df, \n",
        "                         commission=0, serial=False)])\n",
        "test_env = DummyVecEnv([lambda: BitcoinTradingEnv(test_df, \n",
        "                        commission=0, serial=True)])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-29de5c339e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslice_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mslice_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_env = DummyVecEnv([lambda: BitcoinTradingEnv(train_df, \n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBLZPgsvI9_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d22f5ccb-3e3d-4466-f0e9-2f081f01d5b7"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md  LICENSE      requirements.txt  Welcome_To_Colaboratory.ipynb\n",
            "\u001b[0m\u001b[01;34mdocker\u001b[0m/          Makefile     setup.cfg\n",
            "\u001b[01;34mdocs\u001b[0m/            MANIFEST.in  setup.py\n",
            "\u001b[01;34mexamples\u001b[0m/        README.md    \u001b[01;34mtensortrade\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGP8Pp5GFs8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = PPO2(MlpPolicy,\n",
        "             train_env,\n",
        "             verbose=1, \n",
        "             tensorboard_log=\"./tensorboard/\")\n",
        "model.learn(total_timesteps=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}